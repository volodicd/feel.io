# feel.io
An incredible AI to detect emotions from the different sources

This is a project for a deep learning course. The decided topic is an app that detects emotions from different sources, such as sound, photos, or videos.  Model can use either one or more sources for detection. 
The result of this project would be a model with a user app that will use this model.


#Project Type
There are some implementations of such AI as “Affectiva's emotion API” and “DeepEmotion”, which can detect emotions from multiple sources, but this field has not been fully explored yet. 
Although, there was a traditional way to detect emotions, like the Gabor filter[1] with the classification, after the CNN[2] implementation, which was more efficient I cannot call it a classical method nowadays. Therefore, I can classify my project either as “Bring your own method” or “Beat the classics”. Despite this, it is worth noting that I will still consider the main goal as “Bring your own method”, but also will compare it to the “traditional” one in the end.

#Datasets
Several datasets will be used for training, as multiple sources will be used. List is not completed yet, as I’m still thinking about ways to combine several different datasets. 

Developing process


[1] https://www.sciencedirect.com/science/article/abs/pii/S0045790621001890
